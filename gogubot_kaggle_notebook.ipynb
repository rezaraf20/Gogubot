# Gogubot - The Google Services Assistant

This notebook demonstrates a simple RAG-based chatbot that helps users understand and use Google services (Docs, Gmail, Calendar, Drive, etc.) using Gemini Embeddings + FAISS.

!pip install -q faiss-cpu google-generativeai

from kaggle_secrets import UserSecretsClient
import os

GOOGLE_API_KEY = UserSecretsClient().get_secret("GOOGLE_API_KEY")
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

import json
import google.generativeai as genai

genai.configure(api_key=GOOGLE_API_KEY)

with open("/kaggle/input/google-help-data-extended/google_help_data_extended.json", "r") as f:
    help_data = json.load(f)

embeddings = []
for entry in help_data:
    res = genai.embed_content(
        model="models/embedding-001",
        content=entry["content"],
        task_type="retrieval_document"
    )
    entry["embedding"] = res["embedding"]
    embeddings.append(res["embedding"])

import faiss
import numpy as np

index = faiss.IndexFlatL2(len(embeddings[0]))
index.add(np.array(embeddings))

def answer_question(query, k=1):
    res = genai.embed_content(
        model="models/embedding-001",
        content=query,
        task_type="retrieval_query"
    )
    query_vector = np.array([res["embedding"]])
    D, I = index.search(query_vector, k)
    
    for i in I[0]:
        matched = help_data[i]
        print(f"{matched['title']} ({matched['service']})\n{matched['content']}\n")

## Summary

Gogubot shows how LLM embeddings + vector search can build an intelligent assistant over static help content.
Next steps: Streamlit UI, RAG + Gemini Response, real-time integration.
